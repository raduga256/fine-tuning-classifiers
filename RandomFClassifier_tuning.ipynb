{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RandomFClassifier_tuning.ipynb",
      "provenance": [],
      "mount_file_id": "1ou82SUfD2yA1fq965NG-3fqY7yI05EqY",
      "authorship_tag": "ABX9TyP1amNZgSN7BnJtDbG7hCZA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raduga256/fine-tuning-classifiers/blob/main/RandomFClassifier_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kY9Z18XRxo_u"
      },
      "source": [
        "my aim was not to build a robust classifier, rather I wanted to show the practicality of optimizing a classifier for sensitivity. In figure A below, the goal is to move the decision threshold to the left. This minimizes false negatives, which are especially troublesome in the dataset chosen for this post. It contains features from images of 357 benign and 212 malignant breast biopsies. A false negative sample equates to missing a diagnosis of a malignant tumor. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqlOfJOFyazJ"
      },
      "source": [
        "With scikit-learn, tuning a classifier for recall can be achieved in (at least) two main steps.\n",
        "Using GridSearchCV to tune your model by searching for the best hyperparameters and keeping the classifier with the highest recall score.\n",
        "Adjust the decision threshold using the precision-recall curve and the roc curve, which is a more involved method.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SiUv-cCynDT"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geRLmlj7wHhd"
      },
      "source": [
        "# Start by loading the necessary libraries and the data.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve, auc, make_scorer, recall_score, accuracy_score, precision_score, confusion_matrix\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"ggplot\")\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/breast_cancer_dataset.csv\")\n",
        "df2 = df"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "dJ4Z-lKn0Y6l",
        "outputId": "6a56c77b-63cf-4458-ffd6-8fe9368e56f7"
      },
      "source": [
        "df2.sample(5)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>905686</td>\n",
              "      <td>B</td>\n",
              "      <td>11.890</td>\n",
              "      <td>21.17</td>\n",
              "      <td>76.39</td>\n",
              "      <td>433.8</td>\n",
              "      <td>0.09773</td>\n",
              "      <td>0.08120</td>\n",
              "      <td>0.02555</td>\n",
              "      <td>0.02179</td>\n",
              "      <td>0.2019</td>\n",
              "      <td>0.06290</td>\n",
              "      <td>0.2747</td>\n",
              "      <td>1.2030</td>\n",
              "      <td>1.930</td>\n",
              "      <td>19.53</td>\n",
              "      <td>0.009895</td>\n",
              "      <td>0.030530</td>\n",
              "      <td>0.01630</td>\n",
              "      <td>0.009276</td>\n",
              "      <td>0.02258</td>\n",
              "      <td>0.002272</td>\n",
              "      <td>13.050</td>\n",
              "      <td>27.21</td>\n",
              "      <td>85.09</td>\n",
              "      <td>522.9</td>\n",
              "      <td>0.14260</td>\n",
              "      <td>0.21870</td>\n",
              "      <td>0.1164</td>\n",
              "      <td>0.08263</td>\n",
              "      <td>0.3075</td>\n",
              "      <td>0.07351</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>872113</td>\n",
              "      <td>B</td>\n",
              "      <td>8.671</td>\n",
              "      <td>14.45</td>\n",
              "      <td>54.42</td>\n",
              "      <td>227.2</td>\n",
              "      <td>0.09138</td>\n",
              "      <td>0.04276</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1722</td>\n",
              "      <td>0.06724</td>\n",
              "      <td>0.2204</td>\n",
              "      <td>0.7873</td>\n",
              "      <td>1.435</td>\n",
              "      <td>11.36</td>\n",
              "      <td>0.009172</td>\n",
              "      <td>0.008007</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.02711</td>\n",
              "      <td>0.003399</td>\n",
              "      <td>9.262</td>\n",
              "      <td>17.04</td>\n",
              "      <td>58.36</td>\n",
              "      <td>259.2</td>\n",
              "      <td>0.11620</td>\n",
              "      <td>0.07057</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.2592</td>\n",
              "      <td>0.07848</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>545</th>\n",
              "      <td>922576</td>\n",
              "      <td>B</td>\n",
              "      <td>13.620</td>\n",
              "      <td>23.23</td>\n",
              "      <td>87.19</td>\n",
              "      <td>573.2</td>\n",
              "      <td>0.09246</td>\n",
              "      <td>0.06747</td>\n",
              "      <td>0.02974</td>\n",
              "      <td>0.02443</td>\n",
              "      <td>0.1664</td>\n",
              "      <td>0.05801</td>\n",
              "      <td>0.3460</td>\n",
              "      <td>1.3360</td>\n",
              "      <td>2.066</td>\n",
              "      <td>31.24</td>\n",
              "      <td>0.005868</td>\n",
              "      <td>0.020990</td>\n",
              "      <td>0.02021</td>\n",
              "      <td>0.009064</td>\n",
              "      <td>0.02087</td>\n",
              "      <td>0.002583</td>\n",
              "      <td>15.350</td>\n",
              "      <td>29.09</td>\n",
              "      <td>97.58</td>\n",
              "      <td>729.8</td>\n",
              "      <td>0.12160</td>\n",
              "      <td>0.15170</td>\n",
              "      <td>0.1049</td>\n",
              "      <td>0.07174</td>\n",
              "      <td>0.2642</td>\n",
              "      <td>0.06953</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>8711216</td>\n",
              "      <td>B</td>\n",
              "      <td>16.840</td>\n",
              "      <td>19.46</td>\n",
              "      <td>108.40</td>\n",
              "      <td>880.2</td>\n",
              "      <td>0.07445</td>\n",
              "      <td>0.07223</td>\n",
              "      <td>0.05150</td>\n",
              "      <td>0.02771</td>\n",
              "      <td>0.1844</td>\n",
              "      <td>0.05268</td>\n",
              "      <td>0.4789</td>\n",
              "      <td>2.0600</td>\n",
              "      <td>3.479</td>\n",
              "      <td>46.61</td>\n",
              "      <td>0.003443</td>\n",
              "      <td>0.026610</td>\n",
              "      <td>0.03056</td>\n",
              "      <td>0.011100</td>\n",
              "      <td>0.01520</td>\n",
              "      <td>0.001519</td>\n",
              "      <td>18.220</td>\n",
              "      <td>28.07</td>\n",
              "      <td>120.30</td>\n",
              "      <td>1032.0</td>\n",
              "      <td>0.08774</td>\n",
              "      <td>0.17100</td>\n",
              "      <td>0.1882</td>\n",
              "      <td>0.08436</td>\n",
              "      <td>0.2527</td>\n",
              "      <td>0.05972</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>916799</td>\n",
              "      <td>M</td>\n",
              "      <td>18.310</td>\n",
              "      <td>20.58</td>\n",
              "      <td>120.80</td>\n",
              "      <td>1052.0</td>\n",
              "      <td>0.10680</td>\n",
              "      <td>0.12480</td>\n",
              "      <td>0.15690</td>\n",
              "      <td>0.09451</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.05941</td>\n",
              "      <td>0.5449</td>\n",
              "      <td>0.9225</td>\n",
              "      <td>3.218</td>\n",
              "      <td>67.36</td>\n",
              "      <td>0.006176</td>\n",
              "      <td>0.018770</td>\n",
              "      <td>0.02913</td>\n",
              "      <td>0.010460</td>\n",
              "      <td>0.01559</td>\n",
              "      <td>0.002725</td>\n",
              "      <td>21.860</td>\n",
              "      <td>26.20</td>\n",
              "      <td>142.20</td>\n",
              "      <td>1493.0</td>\n",
              "      <td>0.14920</td>\n",
              "      <td>0.25360</td>\n",
              "      <td>0.3759</td>\n",
              "      <td>0.15100</td>\n",
              "      <td>0.3074</td>\n",
              "      <td>0.07863</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id diagnosis  ...  fractal_dimension_worst  Unnamed: 32\n",
              "415   905686         B  ...                  0.07351          NaN\n",
              "175   872113         B  ...                  0.07848          NaN\n",
              "545   922576         B  ...                  0.06953          NaN\n",
              "157  8711216         B  ...                  0.05972          NaN\n",
              "516   916799         M  ...                  0.07863          NaN\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dILBH3a0sfD"
      },
      "source": [
        "The class distribution can be found by counting the diagnosis column. B for benign and M for malignant."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "id": "0bnCcT8t0vKO",
        "outputId": "a0fa6976-dec9-4e84-f717-b54911f3f5d4"
      },
      "source": [
        "df['diagnosis'].value_counts"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2898\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'diagnosis'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-9b93db594c0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'diagnosis'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2898\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2900\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2902\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'diagnosis'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ux0rXWp2Lpt"
      },
      "source": [
        "Convert the class labels and split the data into training and test sets. train_test_split with stratify=True results in consistent class distribution between training and test sets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sn0WZslC2PCU"
      },
      "source": [
        "# by default majority class(benign) will be negative\n",
        "lb = LabelBinarizer()\n",
        "df['diagnosis'] = lb.fit_transform(df['diagnosis'].values)\n",
        "targets = df['diagnosis']\n",
        "\n",
        "df.drop(['id', 'diagnosis', 'Unnamed: 32'], axis=1, inplace=True)\n",
        "\n",
        "#train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df, targets, stratify=targets, random_state=42)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IDdo92j7KOP",
        "outputId": "ef11ec2c-adb2-4927-d565-820e83c321bd"
      },
      "source": [
        "# show the distribution\n",
        "print('y_train class distribution')\n",
        "print(y_train.value_counts(normalize=True))\n",
        "\n",
        "print('y_test class distribution')\n",
        "print(y_test.value_counts(normalize=True))\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_train class distribution\n",
            "0    0.626761\n",
            "1    0.373239\n",
            "Name: diagnosis, dtype: float64\n",
            "y_test class distribution\n",
            "0    0.629371\n",
            "1    0.370629\n",
            "Name: diagnosis, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRdoOMjF9iEm"
      },
      "source": [
        "Now that the data has been prepared, the classifier can be built."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncL6wi2V9k8D"
      },
      "source": [
        "## First strategy: Optimize for sensitivity using GridSearchCV with the scoring argument.\n",
        "\n",
        "First build a generic classifier and setup a parameter grid; random forests have many tunable parameters, which make it suitable for GridSearchCV. The scorers dictionary can be used as the scoring argument in GridSearchCV. When multiple scores are passed, GridSearchCV.cv_results_ will return scoring metrics for each of the score types provided."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhW6n2Hx92rK"
      },
      "source": [
        "clf = RandomForestClassifier()\n",
        "\n",
        "param_grid = {\n",
        "    'min_samples_split': [3, 5 , 10],\n",
        "    'n_estimators': [100, 300],\n",
        "    'max_depth':[3, 5, 15, 25],\n",
        "    'max_features': [3, 5, 10, 20]\n",
        "}\n",
        "\n",
        "scorers = {\n",
        "    'precision_score': make_scorer(precision_score),\n",
        "    'recall_score': make_scorer(recall_score),\n",
        "    'accuracy_score': make_scorer(accuracy_score)\n",
        "}"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35TMewszA5q-"
      },
      "source": [
        "The function below uses GridSearchCV to fit several classifiers according to the combinations of parameters in the param_grid. The scores from scorers are recorded and the best model (as scored by the refit argument) will be selected and \"refit\" to the full training data for downstream use. This also makes predictions on the held out X_test and prints the confusion matrix to show performance.\n",
        "The point of the wrapper function is to quickly reuse the code to fit the best classifier according to the type of scoring metric chosen. First, try precision_score, which should limit the number of false positives. This isn't well-suited for the goal of maxium sensitivity, but allows us to quickly show the difference between a classifier optimized for precision_score and one optimized for recall_score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShEygJUwA8gG"
      },
      "source": [
        "def grid_search_wrapper(refit_score='precision_score'):\n",
        "  \"\"\"\n",
        "  fits a GridSearchCV classifier using refit_score for optimisation\n",
        "  prints classifier performance metrics\n",
        "  \"\"\"\n",
        "  skf = StratifiedKFold(n_splits=10)\n",
        "  grid_search = GridSearchCV(clf, param_grid, scoring=scorers, refit=refit_score, cv=skf, return_train_score=True, n_jobs=-1)\n",
        "  grid_search.fit(X_train.values, y_train.values)\n",
        "\n",
        "  #make the predictions\n",
        "  y_pred = grid_search.predict(X_test.values)\n",
        "\n",
        "  print('Best params for {}'.format(refit_score))\n",
        "  print(grid_search.best_params_)\n",
        "\n",
        "  # confusion matrix on the test data\n",
        "  print('\\nConfusion matrix of Random Forest optimised for {} on the test data:'.format(refit_score))\n",
        "  print(pd.DataFrame(confusion_matrix(y_test, y_pred), columns=['pred_neg', 'pred_pos'], index=['neg','pos']))\n",
        "\n",
        "  return grid_search"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCmmvKwhGEMP",
        "outputId": "d0ce00da-18ed-4ed2-b7a6-4411fec1c5f4"
      },
      "source": [
        "grid_search_clf = grid_search_wrapper(refit_score='precision_score')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best params for precision_score\n",
            "{'max_depth': 3, 'max_features': 20, 'min_samples_split': 10, 'n_estimators': 100}\n",
            "\n",
            "Confusion matrix of Random Forest optimised for precision_score on the test data:\n",
            "     pred_neg  pred_pos\n",
            "neg        90         0\n",
            "pos         6        47\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}